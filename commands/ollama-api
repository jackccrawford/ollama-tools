#!/bin/bash

# ollama-api: A script to send prompts to local Ollama models via HTTP API
# -----------------------------------------------------------------------

# Default values
MODEL="phi4"
INSTANCE=0
PORT=$((11434 + $INSTANCE))
SYSTEM_PROMPT="You are a helpful AI assistant providing a second opinion."
TEMPERATURE=0.7
MAX_TOKENS=2048

# Help message
show_help() {
  echo "Usage: ollama-api [OPTIONS] PROMPT"
  echo
  echo "Send a prompt to a local Ollama model and get a response via HTTP API"
  echo
  echo "Options:"
  echo "  -m, --model MODEL       Specify model (default: phi4)"
  echo "  -i, --instance NUMBER   Specify instance number 0-3 (default: 0)"
  echo "  -s, --system PROMPT     Specify system prompt"
  echo "  -t, --temperature VALUE Set temperature (default: 0.7)"
  echo "  -o, --tokens NUMBER     Set max tokens (default: 2048)"
  echo "  -h, --help              Show this help message"
  echo
  echo "Available models: (use 'ollama list' to see all)"
  echo "  phi4, phi4-mini, r1-1776, llama3.2-vision, dolphin3, mistral, etc."
  echo
  echo "Examples:"
  echo "  ollama-api \"What is the capital of France?\""
  echo "  ollama-api -m mistral -i 1 \"Write a poem about AI\""
  echo "  ollama-api -m phi4 -s \"You are a helpful coding assistant\" \"How do I read a file in Python?\""
  exit 0
}

# Parse arguments
while [[ $# -gt 0 ]]; do
  case "$1" in
    -m|--model)
      MODEL="$2"
      shift 2
      ;;
    -i|--instance)
      INSTANCE="$2"
      if ! [[ "$INSTANCE" =~ ^[0-3]$ ]]; then
        echo "Error: Instance must be a number between 0 and 3"
        exit 1
      fi
      PORT=$((11434 + $INSTANCE))
      shift 2
      ;;
    -s|--system)
      SYSTEM_PROMPT="$2"
      shift 2
      ;;
    -t|--temperature)
      TEMPERATURE="$2"
      shift 2
      ;;
    -o|--tokens)
      MAX_TOKENS="$2"
      shift 2
      ;;
    -h|--help)
      show_help
      ;;
    *)
      PROMPT="$*"
      break
      ;;
  esac
done

# Check if a prompt was provided
if [ -z "$PROMPT" ]; then
  echo "Error: No prompt provided"
  show_help
fi

# Prepare the JSON payload
JSON_PAYLOAD=$(cat <<EOF
{
  "model": "$MODEL",
  "messages": [
    {
      "role": "system",
      "content": "$SYSTEM_PROMPT"
    },
    {
      "role": "user",
      "content": "$PROMPT"
    }
  ],
  "stream": false,
  "temperature": $TEMPERATURE,
  "max_tokens": $MAX_TOKENS
}
EOF
)

echo "=== Sending request to $MODEL on instance $INSTANCE (port $PORT) ==="
echo "Prompt: $PROMPT"
echo "System: $SYSTEM_PROMPT"
echo "------------------------------------------------"

# Send the request and parse the JSON response to extract just the content
RESPONSE=$(curl -s "http://localhost:$PORT/api/chat" \
     -H "Content-Type: application/json" \
     -d "$JSON_PAYLOAD" | jq -r '.message.content')

echo "$RESPONSE"
